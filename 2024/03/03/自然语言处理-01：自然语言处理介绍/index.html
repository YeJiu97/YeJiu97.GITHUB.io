<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.13.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="自然语言处理介绍">
<meta property="og:type" content="article">
<meta property="og:title" content="自然语言处理 01：自然语言处理介绍">
<meta property="og:url" content="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-01%EF%BC%9A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D/index.html">
<meta property="og:site_name" content="夜久">
<meta property="og:description" content="自然语言处理介绍">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-01%EF%BC%9A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D/image-20240303154755596.png">
<meta property="og:image" content="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-01%EF%BC%9A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D/image-20240303162518422.png">
<meta property="og:image" content="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-01%EF%BC%9A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D/image-20240303162702975.png">
<meta property="og:image" content="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-01%EF%BC%9A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D/image-20240303163722854.png">
<meta property="og:image" content="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-01%EF%BC%9A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D/image-20240303164126043.png">
<meta property="article:published_time" content="2024-03-03T12:03:35.000Z">
<meta property="article:modified_time" content="2024-03-03T12:04:59.040Z">
<meta property="article:author" content="Ye Jiu">
<meta property="article:tag" content="自然语言处理">
<meta property="article:tag" content="NPL">
<meta property="article:tag" content="人工智能">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-01%EF%BC%9A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D/image-20240303154755596.png">


<link rel="canonical" href="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-01%EF%BC%9A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-01%EF%BC%9A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D/","path":"2024/03/03/自然语言处理-01：自然语言处理介绍/","title":"自然语言处理 01：自然语言处理介绍"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>自然语言处理 01：自然语言处理介绍 | 夜久</title>
  






  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">夜久</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-about"><a href="/about" rel="section">About</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section">Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories" rel="section">Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section">Archives</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

<iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/848368468&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true"></iframe><div style="font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;"><a href="https://soundcloud.com/terence-vassallo-415912750" title="Ocelotter" target="_blank" style="color: #cccccc; text-decoration: none;">Ocelotter</a> · <a href="https://soundcloud.com/terence-vassallo-415912750/euphoria" title="Euphoria - 楽園の扉 中日字幕" target="_blank" style="color: #cccccc; text-decoration: none;">Euphoria - 楽園の扉 中日字幕</a></div>

<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=535990&auto=1&height=66"></iframe>

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%AC%E5%91%A8%E4%BB%BB%E5%8A%A1"><span class="nav-number">1.</span> <span class="nav-text">本周任务</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%8D%E5%90%91%E9%87%8F"><span class="nav-number">2.</span> <span class="nav-text">词向量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B7%A5%E5%85%B7%E4%B8%8E%E7%AE%97%E6%B3%95"><span class="nav-number">3.</span> <span class="nav-text">工具与算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E5%85%B7%E4%BD%93%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="nav-number">4.</span> <span class="nav-text">一些具体的例子</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">5.</span> <span class="nav-text">神经网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98"><span class="nav-number">6.</span> <span class="nav-text">一些问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BB%E9%A2%98%E7%9F%A5%E8%AF%86%E7%82%B9"><span class="nav-number">7.</span> <span class="nav-text">主题知识点</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ye Jiu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags">
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-01%EF%BC%9A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ye Jiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="夜久">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="自然语言处理 01：自然语言处理介绍 | 夜久">
      <meta itemprop="description" content="自然语言处理介绍">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          自然语言处理 01：自然语言处理介绍
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-03-03 22:33:35 / Modified: 22:34:59" itemprop="dateCreated datePublished" datetime="2024-03-03T22:33:35+10:30">2024-03-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" itemprop="url" rel="index"><span itemprop="name">自然语言处理</span></a>
        </span>
    </span>

  
</div>

            <div class="post-description">自然语言处理介绍</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="本周任务"><a href="#本周任务" class="headerlink" title="本周任务"></a>本周任务</h2><p>到本周末，将能够：</p>
<ul>
<li>解释基本语言术语及其之间的关系</li>
<li>解释如何创建词向量模型 </li>
<li>讨论词向量的可能应用 </li>
<li>使用预先训练的词向量来查找语义相关的词。</li>
</ul>
<p>下面列出了需要完成的任务。</p>
<ol>
<li><strong>完成<a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/assignments/382141">介绍性测验</a></strong></li>
<li>在参加讲座之前，请查看本模块中的在线学习内容并按照指示完成活动。</li>
<li>阅读评估要求。</li>
<li>将的任何问题发布到 Piazza 讨论区。</li>
<li>参加互动讲座。</li>
<li>完成每周测验</li>
</ol>
<p>测试结果：</p>
<p><img src="/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-01%EF%BC%9A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D/image-20240303154755596.png" alt="image-20240303154755596"></p>
<p>要理解本模块中的概念，需要应用以下主题的知识。</p>
<p><strong>机器学习：</strong></p>
<ul>
<li>分类：分类是一种机器学习任务，旨在将数据实例划分为预定义的类别或标签。分类算法根据已知的特征将数据分配到离散的类别中。</li>
<li>回归（逻辑回归）：回归是一种机器学习任务，旨在预测连续型变量的输出。逻辑回归是一种用于二分类问题的回归算法，通过将输入特征的线性组合传递给一个逻辑函数来预测输出的概率。</li>
<li>聚类：聚类是一种无监督学习任务，旨在将数据集中的数据分成不同的组（或簇），使得同一组内的数据之间的相似度高于不同组之间的相似度。</li>
<li>监督机器学习：监督机器学习是一种机器学习范式，其中模型从带有标签的训练数据中学习，并尝试预测未标记数据的标签。监督学习的目标是根据输入特征预测输出标签或值。</li>
<li>无监督机器学习：无监督机器学习是一种机器学习范式，其中模型从不带标签的数据中学习，并试图发现数据中的结构或模式。无监督学习的目标是发现数据中的隐藏关系或结构，而不是预测标签或值。</li>
<li>成本函数：成本函数是用来衡量机器学习模型预测与实际目标之间差异的函数。在训练过程中，优化算法尝试最小化成本函数，以使模型的预测结果与真实值尽可能接近。</li>
</ul>
<p><strong>机器学习方法论：</strong></p>
<ul>
<li>训练、验证和测试：训练、验证和测试是机器学习模型开发过程中的三个关键阶段。训练阶段用于训练模型参数，验证阶段用于调整模型超参数和评估模型性能，测试阶段用于评估模型的泛化性能。</li>
<li>交叉验证：交叉验证是一种评估模型性能和选择模型超参数的技术。它将数据集分成 k 个子集，每次使用其中的一个子集作为验证集，其余的作为训练集，重复 k 次后取平均值作为最终性能评估指标。</li>
<li>精确率、召回率和 F1 指标：精确率衡量的是模型预测为正类别的样本中实际为正类别的比例，召回率衡量的是实际为正类别的样本中被模型正确预测为正类别的比例，F1 指标是精确率和召回率的调和平均数，综合评估了模型的预测性能。</li>
<li>模型欠拟合和过拟合：模型欠拟合指模型对训练数据和测试数据都表现不佳，未能捕获数据中的趋势和模式；模型过拟合指模型在训练数据上表现很好，但在测试数据上表现较差，过度拟合了训练数据中的噪声或特定特征。</li>
<li>模型评估中的偏差和方差：在模型评估中，偏差是指模型的预测值与真实值之间的差异，反映了模型的拟合能力；方差是指模型在不同数据集上预测结果的变化程度，反映了模型的稳定性。偏差-方差权衡是指在模型选择和优化中需要平衡偏差和方差之间的关系，以获得更好的泛化性能。</li>
</ul>
<p>交叉验证是在机器学习中评估模型性能和选择模型超参数的常用技术。以下是使用交叉验证的情况和原因：</p>
<ol>
<li><strong>评估模型性能</strong>：交叉验证可用于评估模型在未见过的数据上的性能。通过将数据集划分为训练集和验证集，可以多次训练模型并评估其性能，从而得到更稳健和可靠的性能评估。</li>
<li><strong>选择模型超参数</strong>：交叉验证可用于选择模型的超参数。通过尝试不同的超参数组合并使用交叉验证评估每个组合的性能，可以找到最佳的超参数设置，以提高模型的泛化能力。</li>
<li><strong>防止过拟合</strong>：交叉验证可以帮助检测和减轻过拟合问题。通过在不同的数据子集上训练和验证模型，可以更好地了解模型对数据的泛化能力，避免模型过度拟合训练数据。</li>
<li><strong>数据利用率高</strong>：交叉验证充分利用了数据集中的所有样本，尤其在数据量较小的情况下，可以提供更可靠的模型评估结果。</li>
</ol>
<h2 id="词向量"><a href="#词向量" class="headerlink" title="词向量"></a>词向量</h2><p>词向量是预先训练的模型，可根据词在向量空间中的距离查找语义相关的词。训练结果是一组向量。每个向量都有 N 个数字，它们是 N 维空间中的坐标。语义相似的向量在这个空间中很接近。</p>
<p>一个演示网站：<a target="_blank" rel="noopener" href="http://vectors.nlpl.eu/explore/embeddings/en/#%E3%80%82">http://vectors.nlpl.eu/explore/embeddings/en/#。</a></p>
<p>另外一个有趣的工具：<a target="_blank" rel="noopener" href="https://ronxin.github.io/wevi/">https://ronxin.github.io/wevi/</a></p>
<p>使用最广泛的 WV 模型，特别注意它们的训练方式：Skip-Gram 和 GloVe。</p>
<table>
<thead>
<tr>
<th>特征</th>
<th>Skip-Gram</th>
<th>GloVe</th>
</tr>
</thead>
<tbody><tr>
<td>训练方式</td>
<td>基于中心词预测上下文词</td>
<td>基于全局词共现矩阵</td>
</tr>
<tr>
<td>模型原理</td>
<td>基于神经网络</td>
<td>基于全局词共现统计信息</td>
</tr>
<tr>
<td>计算效率</td>
<td>训练过程可能较耗时</td>
<td>可能更高效，基于矩阵分解</td>
</tr>
<tr>
<td>数据需求</td>
<td>需要大量数据训练良好的词向量</td>
<td>对全局统计信息依赖较大，但对小数据集也适用</td>
</tr>
<tr>
<td>适用场景</td>
<td>大型语料库，复杂语义表示</td>
<td>语料库规模不大，需求较简单的语义表示</td>
</tr>
</tbody></table>
<p>词向量是词的表示。每个单词都是 N 维向量空间中的一个点。最重要的是，意义相近的单词彼此之间的距离也很近。当我们想要找到相似的单词时，单词向量的这个属性非常有用，例如与未知单词相似的单词，我们将在下一个模块中探索这些单词。</p>
<p>关于词向量：</p>
<blockquote>
<p>词向量是一种将单词映射到高维向量空间中的表示方法。在这个向量空间中，每个单词都被表示为一个向量，而这些向量的维度通常由预先定义的模型决定，比如100维或300维等。</p>
<p>这种表示方法的核心思想是利用单词在上下文中的分布来确定其向量表示，即假设在语言中，具有相似上下文的单词也会有相似的向量表示。</p>
</blockquote>
<p>举例来说，假设我们有一个简单的语料库：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;I love natural language processing&quot;</span><br></pre></td></tr></table></figure>

<p>我们可以将每个单词表示为一个向量，例如：</p>
<ul>
<li>“I” -&gt; [0.2, 0.3, 0.5]</li>
<li>“love” -&gt; [0.1, 0.4, 0.8]</li>
<li>“natural” -&gt; [0.7, 0.9, 0.2]</li>
<li>“language” -&gt; [0.6, 0.3, 0.1]</li>
<li>“processing” -&gt; [0.5, 0.7, 0.6]</li>
</ul>
<p>在这个例子中，每个单词都被表示为一个3维向量。这些向量可以捕捉到单词之间的语义和语法关系，比如”love”和”language”可能在向量空间中更接近，而”natural”和”processing”可能也会有一定的相似性。</p>
<p>通过将单词表示为向量，我们可以在向量空间中进行各种操作，比如计算词语之间的相似度、查找与给定词语最相似的词语等。这种表示方法在自然语言处理中被广泛应用，尤其是在词嵌入（Word Embedding）技术中，如Word2Vec、GloVe等。</p>
<p><strong>如何确定单词对应的向量：</strong></p>
<blockquote>
<p>词向量中每个数字的确定通常是通过训练模型来实现的，其中最常见的模型包括Word2Vec、GloVe、FastText等。这些模型使用了大量的文本数据，并利用神经网络或其他统计方法来学习单词的向量表示。</p>
<p>具体地说，这些模型会考虑单词在上下文中的分布情况，通过优化某种损失函数，将单词的向量表示调整到使得在语料库中频繁共现的单词在向量空间中距离更接近的情况。换句话说，如果两个单词在语料库中经常出现在相似的上下文中，那么它们在向量空间中的表示也应该更加接近。</p>
<p>训练过程中，模型会不断调整单词向量中每个数字的值，直到达到最优的表示。这些值可能没有特定的物理含义，但它们能够捕捉到单词之间的语义和语法关系，从而在许多自然语言处理任务中都能取得良好的效果。</p>
</blockquote>
<p>在完成在线学习部分的阅读和观看视频时，请注意下面列出的概念，因为它们对于成功完成在线测验和作业非常重要。</p>
<p>下面嵌入的视频提供了 NLP 和语言学的有用介绍：<a target="_blank" rel="noopener" href="https://youtu.be/MPOVoIB4EGw">https://youtu.be/MPOVoIB4EGw</a></p>
<p><strong>NPL金字塔的层次通常如下所示（自下而上）：</strong></p>
<ol>
<li><strong>语言学基础（Linguistic Foundations）</strong>：这是金字塔的基础层。它涵盖了语言学的基本原理，如词法学（词汇分析）、句法学（语法分析）、语音学（声音学）等。</li>
<li><strong>词法分析（Morphological Analysis）</strong>：这一层包括词法分析，即将词汇分解成词干和词缀等基本单位。</li>
<li><strong>句法分析（Syntactic Analysis）</strong>：句法分析涉及对句子结构的分析，包括词语之间的语法关系和句子的句法结构。</li>
<li><strong>语义分析（Semantic Analysis）</strong>：在这一层，系统试图理解句子的意义，包括词语之间的语义关系以及句子的整体含义。</li>
<li><strong>语用分析（Pragmatic Analysis）</strong>：语用分析涉及到语言使用的背景和语境，以及言语行为的目的和意图。</li>
</ol>
<p>在NPL金字塔的顶部，还可以包括更高级的任务，如对话系统、情感分析、文本生成等。</p>
<h2 id="工具与算法"><a href="#工具与算法" class="headerlink" title="工具与算法"></a>工具与算法</h2><p>自然语言处理（NLP）领域有许多库和工具可供使用，涵盖了各种不同的任务和技术。以下是一些常用的NLP库和工具，包括但不限于：</p>
<ol>
<li><strong>NLTK  Natural Language Toolkit</strong>：NLTK是Python中最常用的NLP库之一，提供了丰富的工具和资源，用于词性标注、句法分析、语义分析等任务。</li>
<li><strong>spaCy</strong>：spaCy是另一个流行的Python NLP库，提供了快速的词法分析和句法分析等功能，支持多种自然语言处理任务。</li>
<li><strong>Gensim</strong>：Gensim是用于文本处理和主题建模的Python库，支持词向量表示、文档相似性计算等功能。</li>
<li><strong>Stanford NLP</strong>：Stanford NLP是斯坦福大学开发的一组NLP工具，包括分词器、词性标注器、句法分析器等，提供了Java和Python的接口。</li>
<li><strong>OpenNLP</strong>：OpenNLP是Apache基金会的一个项目，提供了一系列NLP工具，包括分词器、词性标注器、命名实体识别器等。</li>
<li><strong>CoreNLP</strong>：CoreNLP是斯坦福大学的一个NLP工具包，提供了一系列NLP任务的功能，包括句法分析、语义分析、情感分析等。</li>
<li><strong>Spacy</strong>：Spacy是一个用于自然语言处理任务的Python库，具有高效的句法分析和实体识别功能。</li>
<li><strong>TextBlob</strong>：TextBlob是一个简单易用的Python库，提供了文本处理和情感分析等功能。</li>
<li><strong>Word2Vec</strong>：Word2Vec是Google开发的一个词向量表示工具，用于将词语转换为向量表示，常用于词语相似性计算和文本表示。</li>
<li><strong>FastText</strong>：FastText是Facebook开发的一个词向量表示工具，支持快速训练和使用大规模词向量模型。</li>
</ol>
<p><strong>以下是一些常见的NLP算法：</strong></p>
<ol>
<li><strong>维特比算法（Viterbi Algorithm）</strong>：维特比算法是一种动态规划算法，用于在给定隐马尔可夫模型的情况下，寻找最有可能产生观测序列的隐藏状态序列。这个算法通过在状态空间中动态地计算每个时刻的最佳路径来实现。维特比算法通常用于诸如词性标注、语音识别等序列标注任务中。</li>
<li><strong>BOUND-WELCH算法（Baum-Welch Algorithm）</strong>：BOUND-WELCH算法是一种用于隐马尔可夫模型参数估计的期望最大化（EM）算法的特例。它用于通过观测序列学习隐马尔可夫模型的参数，包括状态转移概率和观测概率。BOUND-WELCH算法通过迭代地调整模型参数，使得观测序列出现的概率最大化。这个算法常用于无监督学习的问题，其中隐藏状态是未知的，但可以通过观测序列进行估计。</li>
<li><strong>词袋模型（Bag of Words，BoW）</strong>：将文本表示为单词的集合，忽略单词的顺序和语法结构，常用于文本分类和情感分析等任务。</li>
<li><strong>TF-IDF（Term Frequency-Inverse Document Frequency）</strong>：用于衡量单词在文档中的重要性，通过词频和逆文档频率来计算单词的权重，常用于文本分类和信息检索等任务。</li>
<li><strong>词嵌入（Word Embedding）</strong>：将单词映射到低维向量空间中，以捕捉单词之间的语义关系，常用的词嵌入模型包括Word2Vec、GloVe、FastText等。</li>
<li><strong>序列标注算法（Sequence Labeling）</strong>：用于给定输入序列中的每个单词标注一个标签，常见的序列标注任务包括词性标注、命名实体识别等。</li>
<li><strong>机器翻译算法（Machine Translation）</strong>：将一种自然语言翻译成另一种自然语言的算法，常用的机器翻译模型包括统计机器翻译（SMT）和神经机器翻译（NMT）等。</li>
<li><strong>情感分析算法（Sentiment Analysis）</strong>：用于分析文本中的情感倾向，常见的情感分析技术包括基于词典的方法、机器学习方法和深度学习方法等。</li>
<li><strong>命名实体识别算法（Named Entity Recognition，NER）</strong>：用于识别文本中具有特定意义的命名实体，如人名、地名、组织机构名等。</li>
<li><strong>文本生成算法（Text Generation）</strong>：用于生成符合语法和语义规则的文本，常见的文本生成技术包括基于规则的方法、统计语言模型和深度学习模型等。</li>
<li><strong>关键词提取算法（Keyword Extraction）</strong>：从文本中自动提取关键词或关键短语，常用于文本摘要、信息检索等应用。</li>
<li><strong>情境理解（Discourse Analysis）</strong>：用于理解文本中句子之间的逻辑关系和语义关联，常见的技术包括共指消解、指代消解等。</li>
</ol>
<p>这些算法和技术在NLP领域的不同任务和应用中起着重要作用，可以根据具体的需求和场景选择合适的算法来解决问题。</p>
<h2 id="一些具体的例子"><a href="#一些具体的例子" class="headerlink" title="一些具体的例子"></a>一些具体的例子</h2><p><strong>一个语言学+深度学习的例子：</strong></p>
<p><img src="/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-01%EF%BC%9A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D/image-20240303162518422.png" alt="image-20240303162518422"></p>
<p><strong>一个依存树的例子：</strong></p>
<p><img src="/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-01%EF%BC%9A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D/image-20240303162702975.png" alt="image-20240303162702975"></p>
<p>更加详细的笔记查看：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/mantch/p/12327735.html">https://www.cnblogs.com/mantch/p/12327735.html</a></p>
<p><strong>另外一个是Constituency trees（构成树）。</strong></p>
<p>Constituency trees（构成树）是自然语言处理中一种常用的句法结构表示方法，用于描述句子的成分结构。构成树将句子分解为不同的成分（或短语），并显示它们之间的层次关系。在构成树中，句子被分解为若干个成分，每个成分可以是单词或者更大的短语。这些成分通过树形结构相互连接，其中树的叶子节点对应于句子中的单词，而内部节点表示短语结构。</p>
<p>例如，考虑以下句子：”The cat sat on the mat.”（猫坐在垫子上。）。</p>
<p>构成树的示例可能如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">        Sentence</span><br><span class="line">           |</span><br><span class="line">     ______|______</span><br><span class="line">    |             |</span><br><span class="line">  NP (The)       VP (sat)</span><br><span class="line">    |             |</span><br><span class="line">   / \           / \</span><br><span class="line">Det  N         V   PP</span><br><span class="line"> |   |         |   / \</span><br><span class="line"> the cat      sat  P   NP</span><br><span class="line">               |    |   |</span><br><span class="line">               on   the mat</span><br></pre></td></tr></table></figure>

<p>在这个示例中，构成树以”Sentence”作为根节点，该句子被分解为名词短语（NP）”The cat” 和动词短语（VP）”sat on the mat”。名词短语”NP”由限定词（Det）”The”和名词（N）”cat”组成，动词短语”VP”由动词（V）”sat”和介词短语（PP）”on the mat”组成。</p>
<p>构成树提供了对句子结构的直观理解，有助于理解句子中不同部分之间的语法关系。它在自然语言处理中被广泛应用，例如句法分析、语言生成等任务中。</p>
<p><strong>情感分析（sentiment analysis）</strong></p>
<p>情感分析（Sentiment Analysis），也称为意见挖掘（Opinion Mining），是一种自然语言处理技术，旨在识别和提取文本中的情感和情绪。它通常用于分析文本的态度、情绪、观点和情感倾向，以了解作者对某个主题或实体的态度是正面的、负面的还是中性的。</p>
<p>情感分析可以应用于各种类型的文本数据，包括社交媒体帖子、产品评论、新闻文章、调查问卷等。它可以帮助企业了解客户对其产品和服务的感受，政府了解公众对政策和事件的反应，以及分析师了解市场情绪和趋势。</p>
<p>情感分析的任务通常包括以下几个方面：</p>
<ol>
<li><strong>情感极性分类</strong>：将文本分类为积极、消极或中性情感。例如，判断一篇产品评论是正面的、负面的还是中性的。</li>
<li><strong>情感强度分析</strong>：确定文本中情感的强度程度。例如，判断一篇评论中的情感是强烈的还是弱化的。</li>
<li><strong>主题情感分析</strong>：针对特定主题或实体分析情感。例如，针对某个产品或品牌进行情感分析，了解公众对其的态度。</li>
<li><strong>情感趋势分析</strong>：分析情感随时间的变化趋势。例如，追踪产品评论的情感趋势，了解产品在市场上的表现如何随着时间推移而变化。</li>
</ol>
<p>一个例子：</p>
<p><img src="/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-01%EF%BC%9A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D/image-20240303163722854.png" alt="image-20240303163722854"></p>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><p>神经网络是受人脑结构启发的计算机模型。神经网络通常简称为神经网络。 </p>
<p>人脑由大约 1000 亿个称为神经元的神经细胞组成，每个神经元都与其他神经元相连。</p>
<p><em>电信号沿着称为树突的</em>通道流入神经元，如果这些电输入的总和超过特定<em>阈值</em>，神经元就会通过称为<em>轴突</em>的通道发出电输出。  </p>
<p>为了在计算机内部构建<em>神经网络，我们只需将这些神经元的集合放在一起，这样一些神经元的输出就会馈送到其他神经元的输入。</em></p>
<p>典型的神经网络具有一个 输入层 （您正在使用的数据中的每个特征有一个输入）、一个 输出层 （每个目标变量有一个输出）以及 中间的一个或多个神经元隐藏层。</p>
<p>每个神经元通过权重连接到其他神经元，权重决定每个神经元对其连接的其他神经元的影响程度。</p>
<p>图示：</p>
<p><img src="/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-01%EF%BC%9A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D/image-20240303164126043.png" alt="image-20240303164126043"></p>
<p>在线调参地址：<a target="_blank" rel="noopener" href="https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.27180&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false">在线调参</a></p>
<p>一些其他的资源：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1mu411x7VD/?spm_id_from=333.337.search-card.all.click">https://www.bilibili.com/video/BV1mu411x7VD/?spm_id_from=333.337.search-card.all.click</a></li>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1bx411M7Zx/?spm_id_from=333.999.0.0&vd_source=70cc82c6f851aaa826e5c863112d2113">https://www.bilibili.com/video/BV1bx411M7Zx/?spm_id_from=333.999.0.0&amp;vd_source=70cc82c6f851aaa826e5c863112d2113</a></li>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ux411j7ri/?spm_id_from=333.999.0.0&vd_source=70cc82c6f851aaa826e5c863112d2113">https://www.bilibili.com/video/BV1Ux411j7ri/?spm_id_from=333.999.0.0&amp;vd_source=70cc82c6f851aaa826e5c863112d2113</a></li>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV16x411V7Qg/?spm_id_from=333.999.0.0&vd_source=70cc82c6f851aaa826e5c863112d2113">https://www.bilibili.com/video/BV16x411V7Qg/?spm_id_from=333.999.0.0&amp;vd_source=70cc82c6f851aaa826e5c863112d2113</a></li>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV16x411V7Qg?p=2&vd_source=70cc82c6f851aaa826e5c863112d2113">https://www.bilibili.com/video/BV16x411V7Qg?p=2&amp;vd_source=70cc82c6f851aaa826e5c863112d2113</a></li>
</ul>
<h2 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h2><p><strong>Explain the difference between semantics and pragmatics and provide examples.</strong></p>
<table>
<thead>
<tr>
<th>概念</th>
<th>语义（semantics ）</th>
<th>语用学（pragmatics）</th>
</tr>
</thead>
<tbody><tr>
<td>定义</td>
<td>研究词语、短语和句子的字面意义</td>
<td>研究言语在实际交流中的使用情境和效果</td>
</tr>
<tr>
<td>焦点</td>
<td>关注语言单位与所表示概念之间的关系</td>
<td>关注言语行为的意图、社会和文化背景以及上下文对语言理解的影响</td>
</tr>
<tr>
<td>示例</td>
<td>“Cat”的语义是一种四肢动物，通常作为宠物饲养</td>
<td>“你好吗？”可能在实际交流中只是一种礼貌问候</td>
</tr>
<tr>
<td>稳定性</td>
<td>相对固定，通常与词语的定义和语法结构相关</td>
<td>更加灵活，受到言外之意、语境和交际目的等因素的影响</td>
</tr>
<tr>
<td>内部&#x2F;外部</td>
<td>语言的内部结构</td>
<td>语言的外部应用和效果</td>
</tr>
</tbody></table>
<p><strong>Identify all the various meanings of the following sentence: ‘one morning I shot an elephant in my pajamas.’</strong></p>
<p>这句话的多重含义可以理解为：</p>
<ol>
<li>“one morning”：这个短语指的是某个早晨，暗示了一个特定的时间点或者事件发生的背景。</li>
<li>“I shot an elephant”：这个短语表达了一个动作，即“我开枪射击了一头大象”。这句话的字面意思是“我在穿着睡衣的情况下开枪射击了一头大象”。</li>
<li>“in my pajamas”：这个短语描述了动作发生的环境，即“我穿着睡衣”。这个短语可以产生歧义，它可以解释为“我穿着睡衣时射击了大象”或者“我在大象穿着睡衣的情况下射击了它”。</li>
</ol>
<p>因此，这句话的多重含义可能是指在某个早晨，有人穿着睡衣时开枪射击了一头大象。这个句子之所以有趣，是因为它可以根据语境产生多种不同的理解。</p>
<p><strong>From the list of words, identify sub-words and morphemes.</strong></p>
<p>Sub-words是指一个词中可以被分解成的较小的语言单元，这些单元可能不是完整的词，但在某种程度上具有一定的语义或语法功能。</p>
<p>Morphemes是语言中的最小的具有意义的单位，它是词的构成部分，可以单独存在或者与其他morphemes组合形成词语。</p>
<p>一些例子：</p>
<ul>
<li>Sub-words：”un-“ 在 “undo” 中是一个sub-word，表示否定或相反的含义。”pre-“ 在 “preview” 中是一个sub-word，表示在前面或提前的含义。</li>
<li>Morphemes：”-ed” 在 “walked” 中是一个morpheme，表示过去时。”-s” 在 “cats” 中是一个morpheme，表示复数形式。</li>
</ul>
<p>**From the sentence explain its meaning in terms of semantics and pragmatics. **</p>
<p>这句话的语义是关于事件的描述，主要涉及到以下几个方面：</p>
<ol>
<li>“one morning” 表示一个具体的时间，即某个早晨。</li>
<li>“I shot an elephant” 描述了一个动作，即说话者开枪射击了一头大象。</li>
<li>“in my pajamas” 描述了动作发生的环境，即说话者穿着睡衣。</li>
</ol>
<p>在语义学的角度上，这句话是一个事件的简单描述，包括时间、动作和环境。</p>
<p>从语用学的角度来看，这句话可能有一些歧义，具体取决于上下文和说话者的意图：</p>
<ol>
<li>“in my pajamas” 这个短语可能引起歧义，因为它可以解释为说话者穿着睡衣时射击大象，也可以解释为说话者在大象穿着睡衣的情况下射击它。这种歧义可能引发听者的笑声，因为它打破了通常的语境预期。</li>
<li>语境的缺失可能导致对事件的理解产生不同的解释。例如，为什么说话者穿着睡衣？是偶然的还是有特殊原因？这些问题可能需要从语境中获取信息，而不仅仅依赖于字面意义。</li>
</ol>
<p>因此，语用学强调了言语行为的意图、言外之意和交际背景，这些因素在理解这句话时可能起到关键作用。</p>
<p><strong>From the sentence, identify parts of speech (POS)</strong>. </p>
<p>这句话中的各个词的词性（Parts of Speech, POS）如下：</p>
<ul>
<li>“one” - 数词（numeral）</li>
<li>“morning” - 名词（noun）</li>
<li>“I” - 代词（pronoun）</li>
<li>“shot” - 动词（verb）</li>
<li>“an” - 冠词（article）</li>
<li>“elephant” - 名词（noun）</li>
<li>“in” - 介词（preposition）</li>
<li>“my” - 代词（pronoun）</li>
<li>“pajamas” - 名词（noun）</li>
</ul>
<p>总体而言，这个句子包含了数词、名词、代词、动词和介词等不同的词性。</p>
<p>**From a list of business problems, identify which ones can be solved using Natural Language Processing. **</p>
<ul>
<li><p>客户支持和服务：通过NLP技术，可以建立智能客服系统来处理客户的问题和需求，例如自动回答常见问题、提供建议、处理投诉等。</p>
</li>
<li><p>市场调研和消费者洞察：NLP可以帮助分析社交媒体上的文本数据，了解消费者对产品和服务的看法，发现趋势和关键主题。</p>
</li>
<li><p>舆情分析和品牌管理：通过分析新闻报道、社交媒体内容和客户反馈等文本数据，可以了解公众对公司和产品的看法，及时发现并应对负面舆情。</p>
</li>
<li><p>市场营销和广告优化：NLP技术可以分析消费者的语言和行为模式，帮助企业定制个性化的营销策略和广告内容，提高营销效果。</p>
</li>
<li><p>文档管理和信息提取：利用NLP技术，可以自动处理和归档大量的文档、合同和报告，实现信息的快速检索和提取。</p>
</li>
<li><p>人才招聘和人力资源管理：NLP可以帮助企业自动筛选简历、分析候选人的语言和技能，提高招聘效率和质量。</p>
</li>
<li><p>知识管理和智能助手：企业可以利用NLP技术构建智能助手，帮助员工快速查找信息、解决问题，提高工作效率。</p>
</li>
<li><p>金融和投资分析：NLP可以分析新闻报道、财报和社交媒体上的信息，帮助投资者做出更准确的决策，发现投资机会和风险。</p>
</li>
</ul>
<p><strong>Evaluate whether the Machine Learning task can be supervised, unsupervised, or a semi-supervised learning problem.</strong></p>
<p>评估机器学习任务是监督学习、无监督学习还是半监督学习问题，需要考虑可用数据的性质以及任务的具体学习目标。</p>
<ol>
<li><strong>监督学习</strong>：<ul>
<li>在监督学习中，算法从带有标签的数据中学习，其中输入数据与相应的目标标签配对。</li>
<li>目标是学习从输入特征到目标标签的映射。</li>
<li>示例包括分类和回归任务。</li>
</ul>
</li>
<li><strong>无监督学习</strong>：<ul>
<li>无监督学习涉及从未标记的数据中学习模式或结构，而没有明确的目标标签。</li>
<li>算法发现数据内部的隐藏模式、群组或聚类。</li>
<li>示例包括聚类、降维和异常检测。</li>
</ul>
</li>
<li><strong>半监督学习</strong>：<ul>
<li>半监督学习介于监督学习和无监督学习之间，算法从标记和未标记数据的组合中学习。</li>
<li>通常，与总数据量相比，标记数据的数量较少。</li>
<li>算法利用额外的未标记数据来提高学习性能或泛化能力。</li>
</ul>
</li>
</ol>
<p>要评估机器学习任务属于哪个类别，我们需要检查可用的数据：</p>
<ul>
<li>如果数据包含输入特征以及相应的目标标签，那么这是一个监督学习问题。</li>
<li>如果数据没有目标标签，且目标是发现数据内部的模式或结构，那么这是一个无监督学习问题。</li>
<li>如果数据包含标记和未标记实例的组合，那么这是一个半监督学习问题。</li>
</ul>
<p>根据数据的特征和学习目标，我们可以确定机器学习任务是监督学习、无监督学习还是半监督学习。</p>
<h2 id="主题知识点"><a href="#主题知识点" class="headerlink" title="主题知识点"></a>主题知识点</h2>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" rel="tag"># 自然语言处理</a>
              <a href="/tags/NPL/" rel="tag"># NPL</a>
              <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" rel="tag"># 人工智能</a>
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-00%EF%BC%9A%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86%E7%82%B9/" rel="prev" title="自然语言处理 00：前置知识点">
                  <i class="fa fa-chevron-left"></i> 自然语言处理 00：前置知识点
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/12/26/%E7%AC%AC%E4%B8%80%E4%B8%AA%E4%BA%BA%E7%94%9F%E4%B8%83%E5%B9%B4%E8%AE%A1%E5%88%92/" rel="next" title="第一个人生七年计划">
                  第一个人生七年计划 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ye Jiu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.5.0/pjax.min.js" integrity="sha256-3NkoLDrmHLTYj7csHIZSr0MHAFTXth7Ua/DDt4MRUAg=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script>

  





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"ams","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
