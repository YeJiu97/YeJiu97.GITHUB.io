<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.13.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="学校的自然语言处理课程的笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="自然语言处理笔记">
<meta property="og:url" content="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="夜久">
<meta property="og:description" content="学校的自然语言处理课程的笔记">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/image-20240303153844956.png">
<meta property="og:image" content="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/image-20240303154755596.png">
<meta property="og:image" content="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/image-20240303162518422.png">
<meta property="og:image" content="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/image-20240303162702975.png">
<meta property="og:image" content="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/image-20240303163722854.png">
<meta property="og:image" content="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/image-20240303164126043.png">
<meta property="article:published_time" content="2024-03-03T04:48:00.000Z">
<meta property="article:modified_time" content="2024-03-03T06:18:36.198Z">
<meta property="article:author" content="Ye Jiu">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="自然语言处理">
<meta property="article:tag" content="人工智能">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/image-20240303153844956.png">


<link rel="canonical" href="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/","path":"2024/03/03/自然语言处理笔记/","title":"自然语言处理笔记"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>自然语言处理笔记 | 夜久</title>
  






  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">夜久</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-about"><a href="/about" rel="section">About</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section">Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories" rel="section">Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section">Archives</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

<iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/848368468&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true"></iframe><div style="font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;"><a href="https://soundcloud.com/terence-vassallo-415912750" title="Ocelotter" target="_blank" style="color: #cccccc; text-decoration: none;">Ocelotter</a> · <a href="https://soundcloud.com/terence-vassallo-415912750/euphoria" title="Euphoria - 楽園の扉 中日字幕" target="_blank" style="color: #cccccc; text-decoration: none;">Euphoria - 楽園の扉 中日字幕</a></div>

<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=535990&auto=1&height=66"></iframe>

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AF%BE%E7%A8%8B%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86"><span class="nav-number">1.</span> <span class="nav-text">课程前置知识</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9F%A5%E8%AF%86%E9%9C%80%E6%B1%82"><span class="nav-number">1.1.</span> <span class="nav-text">知识需求</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8F%90%E4%BE%9B%E8%B5%84%E6%BA%90"><span class="nav-number">1.2.</span> <span class="nav-text">提供资源</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E5%91%A8%E7%9F%A5%E8%AF%86%E7%82%B9"><span class="nav-number">2.</span> <span class="nav-text">第一周知识点</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%AC%E5%91%A8%E4%BB%BB%E5%8A%A1"><span class="nav-number">2.1.</span> <span class="nav-text">本周任务</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%8D%E5%90%91%E9%87%8F"><span class="nav-number">2.2.</span> <span class="nav-text">词向量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B7%A5%E5%85%B7%E4%B8%8E%E7%AE%97%E6%B3%95"><span class="nav-number">2.3.</span> <span class="nav-text">工具与算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E5%85%B7%E4%BD%93%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="nav-number">2.4.</span> <span class="nav-text">一些具体的例子</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">2.5.</span> <span class="nav-text">神经网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98"><span class="nav-number">2.6.</span> <span class="nav-text">一些问题</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ye Jiu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">9</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags">
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ye Jiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="夜久">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="自然语言处理笔记 | 夜久">
      <meta itemprop="description" content="学校的自然语言处理课程的笔记">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          自然语言处理笔记
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-03-03 15:18:00 / Modified: 16:48:36" itemprop="dateCreated datePublished" datetime="2024-03-03T15:18:00+10:30">2024-03-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" itemprop="url" rel="index"><span itemprop="name">自然语言处理</span></a>
        </span>
    </span>

  
</div>

            <div class="post-description">学校的自然语言处理课程的笔记</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="课程前置知识"><a href="#课程前置知识" class="headerlink" title="课程前置知识"></a>课程前置知识</h1><h2 id="知识需求"><a href="#知识需求" class="headerlink" title="知识需求"></a>知识需求</h2><p>编程语言需求：Python语言。</p>
<p>数学知识：数据科学的数学基础。</p>
<ul>
<li><input disabled type="checkbox"> 基础知识：集合、函数、求和</li>
<li><input disabled type="checkbox"> 概率</li>
<li><input disabled type="checkbox"> 朴素贝叶斯定理和分类器</li>
<li><input disabled type="checkbox"> 用矩阵表示数据</li>
<li><input disabled type="checkbox"> 解线性方程</li>
<li><input disabled type="checkbox"> 降维：主成分分析（PCA）</li>
<li><input disabled type="checkbox"> 微积分和梯度下降</li>
</ul>
<p>机器学习与人工智能知识。</p>
<ul>
<li><input disabled type="checkbox"> 线性回归，成本&#x2F;损失函数，均方误差。 </li>
<li><input disabled type="checkbox"> 分类和交叉验证：贝叶斯分类、k-NN（k近邻）、决策树、感知器训练、逻辑回归、支持向量机（SVM）。 </li>
<li><input disabled type="checkbox"> 聚类：k均值。</li>
</ul>
<h2 id="提供资源"><a href="#提供资源" class="headerlink" title="提供资源"></a>提供资源</h2><p><strong>Python和R</strong></p>
<p><a target="_blank" rel="noopener" href="https://www.w3schools.com/python/">W3 Python 教程到外部站点的链接。</a>是刷新 Python 知识的好资源。本教程包含一组页面，涉及 Python 编程中的许多主题，并提供了一个简单的环境来试验 Python 代码。</p>
<p><a target="_blank" rel="noopener" href="https://www.w3schools.com/r/">W3 R教程到外部站点的链接。</a>或者Katya Ognyanova对<a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/77838/files/11103244/download">R 基础知识和可视化工具</a>的精彩介绍。还有一个附带的<a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/77838/files/11103243/download">R 代码</a>。</p>
<p>以下资源将帮助建立&#x2F;修改统计知识。这些是课程中许多主题中使用的重要概念。</p>
<p><strong>统计</strong></p>
<p>总结<a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540179?wrap=1">_</a><a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540179/download?download_frd=1">下载摘要</a>的描述性统计。</p>
<p><img src="/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/image-20240303153844956.png" alt="image-20240303153844956"></p>
<p>DS 摩尔和 GP 麦凯布 (1989)。<a target="_blank" rel="noopener" href="https://adelaide.leganto.exlibrisgroup.com/lti/launch?institute=61ADELAIDE_INST&tool=CANVAS_LTI_v1_1&citation_id=2246282641530001811">统计实践简介到外部站点的链接。</a>。WH 弗里曼&#x2F;时代图书&#x2F;亨利·霍尔特公司</p>
<p>有关统计的其他资源：</p>
<p>其他资源：</p>
<ul>
<li>描述性统计： <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Five-number_summary">https://en.wikipedia.org/wiki/Five-number_summary到外部站点的链接。</a></li>
<li>汇总数据<a target="_blank" rel="noopener" href="https://www.youtube.com/channel/UCxdR3vGHDUYIOm6RqUJxPPg/videos">https://www.youtube.com/channel/UCxdR3vGHDUYIOm6RqUJxPPg/videos到外部站点的链接。</a></li>
<li>形状、分布、异常值<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=Q8b1_dOM8LU">https://www.youtube.com/watch?v=Q8b1_dOM8LU到外部站点的链接。</a></li>
<li>箱形图<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=bhCGIUmZeDE">https://www.youtube.com/watch?v=bhCGIUmZeDE到外部站点的链接。</a></li>
</ul>
<p><strong>概率</strong></p>
<p>以下资源将帮助建立&#x2F;修改有关概率的知识。这些是贝叶斯方法中的重要概念，例如朴素贝叶斯算法。</p>
<p>Deisenroth，国会议员、Faisal，AA 和 Ong，CS (2020)。<a target="_blank" rel="noopener" href="https://adelaide.leganto.exlibrisgroup.com/lti/launch?institute=61ADELAIDE_INST&tool=CANVAS_LTI_v1_1&citation_id=2246282644410001811">机器学习数学到外部站点的链接。</a>，第 1.2 章。剑桥大学出版社。</p>
<p><strong>线性代数和微积分</strong></p>
<p>对于本模块，需要熟悉几个数学主题，其中包括：</p>
<ul>
<li>矩阵求逆和转置</li>
<li>矩阵-矩阵运算</li>
<li>矩阵向量运算</li>
<li>向量点积</li>
<li>偏导数</li>
</ul>
<p>以下<a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540175?wrap=1"><strong>幻灯片</strong></a><a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540175/download?download_frd=1"> 下载幻灯片</a>总结这些基本的数学概念。</p>
<p>这是一个关于矩阵向量乘法的视频：<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=aV-P3mDgK_E">https://www.youtube.com/watch?v=aV-P3mDgK_E到外部站点的链接。</a></p>
<p> 可以在这里找到很好的数学参考：<a target="_blank" rel="noopener" href="http://cs229.stanford.edu/summer2020/cs229-linalg.pdf">http://cs229.stanford.edu/summer2020/cs229-linalg.pdf到外部站点的链接。</a></p>
<p>以下书籍是深入了解数据科学中使用的数学方法的良好学习来源： Sheldon Axler，<a target="_blank" rel="noopener" href="https://adelaide.leganto.exlibrisgroup.com/lti/launch?institute=61ADELAIDE_INST&tool=CANVAS_LTI_v1_1&citation_id=2242923306420001811">线性代数做得正确到外部站点的链接。</a>，第三版，施普林格。</p>
<p><strong>机器学习和神经网络简介</strong></p>
<p>以下书籍是一本很好的机器学习入门读物，可能有助于复习 ML 概念。</p>
<p>Rebala, G.、Ravi, A. 和 Churiwala, S. (2019)。<a target="_blank" rel="noopener" href="https://adelaide.leganto.exlibrisgroup.com/lti/launch?institute=61ADELAIDE_INST&tool=CANVAS_LTI_v1_1&citation_id=2242923306410001811">机器学习简介到外部站点的链接。</a>。施普林格。</p>
<p>如果您只喜欢摘要，这里有关于经典机器学习各种主题的幻灯片：</p>
<p><a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540176?wrap=1">机器学习方法论</a><a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540176/download?download_frd=1">下载机器学习方法</a></p>
<p><a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540180?wrap=1">k-最近邻</a><a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540180/download?download_frd=1">下载 k 最近邻</a></p>
<p><a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540191?wrap=1">朴素贝叶斯方法</a><a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540191/download?download_frd=1">下载朴素贝叶斯方法</a></p>
<p><a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540184?wrap=1"><strong>幻灯片</strong></a><a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540184/download?download_frd=1"> 下载幻灯片</a>总结神经网络的基础知识。</p>
<p><a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540178?wrap=1"><strong>另外，Python代码</strong></a>的示例<a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540178?wrap=1"> </a><a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540178/download?download_frd=1"> 下载代码</a>使用这个**<a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540204?wrap=1">数据集</a><a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/files/14540204/download?download_frd=1"> 下载数据集</a>**用于测试各种机器学习方法。</p>
<p><strong>注意</strong></p>
<p>上述内容我已经下载到传到了Github上面。</p>
<h1 id="第一周知识点"><a href="#第一周知识点" class="headerlink" title="第一周知识点"></a>第一周知识点</h1><h2 id="本周任务"><a href="#本周任务" class="headerlink" title="本周任务"></a>本周任务</h2><p>到本周末，将能够：</p>
<ul>
<li>解释基本语言术语及其之间的关系</li>
<li>解释如何创建词向量模型 </li>
<li>讨论词向量的可能应用 </li>
<li>使用预先训练的词向量来查找语义相关的词。</li>
</ul>
<p>下面列出了需要完成的任务。</p>
<ol>
<li><strong>完成<a target="_blank" rel="noopener" href="https://myuni.adelaide.edu.au/courses/95210/assignments/382141">介绍性测验</a></strong></li>
<li>在参加讲座<strong>之前，</strong>请查看本模块中的在线学习内容并按照指示完成活动。</li>
<li><strong>阅读</strong>评估要求。</li>
<li>将的任何问题发布到 Piazza 讨论区。</li>
<li><strong>参加</strong>互动讲座。</li>
<li><strong>完成</strong>每周测验</li>
</ol>
<p>测试结果：</p>
<p><img src="/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/image-20240303154755596.png" alt="image-20240303154755596"></p>
<p>要理解本模块中的概念，需要应用以下主题的知识。</p>
<p><strong>机器学习：</strong></p>
<ul>
<li><input disabled type="checkbox"> 分类</li>
<li><input disabled type="checkbox"> 回归（逻辑回归） </li>
<li><input disabled type="checkbox"> 聚类 </li>
<li><input disabled type="checkbox"> 监督机器学习</li>
<li><input disabled type="checkbox"> 无监督机器学习</li>
<li><input disabled type="checkbox"> 成本函数</li>
</ul>
<p><strong>机器学习方法论：</strong></p>
<ul>
<li><input disabled type="checkbox"> 训练、验证和测试</li>
<li><input disabled type="checkbox"> 交叉验证</li>
<li><input disabled type="checkbox"> 精确率、召回率和 F1 指标</li>
<li><input disabled type="checkbox"> 模型欠拟合和过拟合</li>
<li><input disabled type="checkbox"> 模型评估中的偏差和方差</li>
</ul>
<h2 id="词向量"><a href="#词向量" class="headerlink" title="词向量"></a>词向量</h2><p>词向量是预先训练的模型，可根据词在向量空间中的距离查找语义相关的词。训练结果是一组向量。每个向量都有 N 个数字，它们是 N 维空间中的坐标。语义相似的向量在这个空间中很接近。</p>
<p>一个演示网站：<a target="_blank" rel="noopener" href="http://vectors.nlpl.eu/explore/embeddings/en/#%E3%80%82">http://vectors.nlpl.eu/explore/embeddings/en/#。</a></p>
<p>另外一个有趣的工具：<a target="_blank" rel="noopener" href="https://ronxin.github.io/wevi/">https://ronxin.github.io/wevi/</a></p>
<p>使用最广泛的 WV 模型，特别注意它们的训练方式：Skip-Gram 和 GloVe。</p>
<table>
<thead>
<tr>
<th>特征</th>
<th>Skip-Gram</th>
<th>GloVe</th>
</tr>
</thead>
<tbody><tr>
<td>训练方式</td>
<td>基于中心词预测上下文词</td>
<td>基于全局词共现矩阵</td>
</tr>
<tr>
<td>模型原理</td>
<td>基于神经网络</td>
<td>基于全局词共现统计信息</td>
</tr>
<tr>
<td>计算效率</td>
<td>训练过程可能较耗时</td>
<td>可能更高效，基于矩阵分解</td>
</tr>
<tr>
<td>数据需求</td>
<td>需要大量数据训练良好的词向量</td>
<td>对全局统计信息依赖较大，但对小数据集也适用</td>
</tr>
<tr>
<td>适用场景</td>
<td>大型语料库，复杂语义表示</td>
<td>语料库规模不大，需求较简单的语义表示</td>
</tr>
</tbody></table>
<p>词向量是词的表示。每个单词都是 N 维向量空间中的一个点。最重要的是，意义相近的单词彼此之间的距离也很近。当我们想要找到相似的单词时，单词向量的这个属性非常有用，例如与未知单词相似的单词，我们将在下一个模块中探索这些单词。</p>
<p>关于词向量：</p>
<blockquote>
<p>词向量是一种将单词映射到高维向量空间中的表示方法。在这个向量空间中，每个单词都被表示为一个向量，而这些向量的维度通常由预先定义的模型决定，比如100维或300维等。</p>
<p>这种表示方法的核心思想是利用单词在上下文中的分布来确定其向量表示，即假设在语言中，具有相似上下文的单词也会有相似的向量表示。</p>
</blockquote>
<p>举例来说，假设我们有一个简单的语料库：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;I love natural language processing&quot;</span><br></pre></td></tr></table></figure>

<p>我们可以将每个单词表示为一个向量，例如：</p>
<ul>
<li>“I” -&gt; [0.2, 0.3, 0.5]</li>
<li>“love” -&gt; [0.1, 0.4, 0.8]</li>
<li>“natural” -&gt; [0.7, 0.9, 0.2]</li>
<li>“language” -&gt; [0.6, 0.3, 0.1]</li>
<li>“processing” -&gt; [0.5, 0.7, 0.6]</li>
</ul>
<p>在这个例子中，每个单词都被表示为一个3维向量。这些向量可以捕捉到单词之间的语义和语法关系，比如”love”和”language”可能在向量空间中更接近，而”natural”和”processing”可能也会有一定的相似性。</p>
<p>通过将单词表示为向量，我们可以在向量空间中进行各种操作，比如计算词语之间的相似度、查找与给定词语最相似的词语等。这种表示方法在自然语言处理中被广泛应用，尤其是在词嵌入（Word Embedding）技术中，如Word2Vec、GloVe等。</p>
<p><strong>如何确定单词对应的向量：</strong></p>
<blockquote>
<p>词向量中每个数字的确定通常是通过训练模型来实现的，其中最常见的模型包括Word2Vec、GloVe、FastText等。这些模型使用了大量的文本数据，并利用神经网络或其他统计方法来学习单词的向量表示。</p>
<p>具体地说，这些模型会考虑单词在上下文中的分布情况，通过优化某种损失函数，将单词的向量表示调整到使得在语料库中频繁共现的单词在向量空间中距离更接近的情况。换句话说，如果两个单词在语料库中经常出现在相似的上下文中，那么它们在向量空间中的表示也应该更加接近。</p>
<p>训练过程中，模型会不断调整单词向量中每个数字的值，直到达到最优的表示。这些值可能没有特定的物理含义，但它们能够捕捉到单词之间的语义和语法关系，从而在许多自然语言处理任务中都能取得良好的效果。</p>
</blockquote>
<p>在完成在线学习部分的阅读和观看视频时，请注意下面列出的概念，因为它们对于成功完成在线测验和作业非常重要。</p>
<p>下面嵌入的视频提供了 NLP 和语言学的有用介绍：<a target="_blank" rel="noopener" href="https://youtu.be/MPOVoIB4EGw">https://youtu.be/MPOVoIB4EGw</a></p>
<p><strong>NPL金字塔的层次通常如下所示（自下而上）：</strong></p>
<ol>
<li><strong>语言学基础（Linguistic Foundations）</strong>：这是金字塔的基础层。它涵盖了语言学的基本原理，如词法学（词汇分析）、句法学（语法分析）、语音学（声音学）等。</li>
<li><strong>词法分析（Morphological Analysis）</strong>：这一层包括词法分析，即将词汇分解成词干和词缀等基本单位。</li>
<li><strong>句法分析（Syntactic Analysis）</strong>：句法分析涉及对句子结构的分析，包括词语之间的语法关系和句子的句法结构。</li>
<li><strong>语义分析（Semantic Analysis）</strong>：在这一层，系统试图理解句子的意义，包括词语之间的语义关系以及句子的整体含义。</li>
<li><strong>语用分析（Pragmatic Analysis）</strong>：语用分析涉及到语言使用的背景和语境，以及言语行为的目的和意图。</li>
</ol>
<p>在NPL金字塔的顶部，还可以包括更高级的任务，如对话系统、情感分析、文本生成等。</p>
<h2 id="工具与算法"><a href="#工具与算法" class="headerlink" title="工具与算法"></a>工具与算法</h2><p>自然语言处理（NLP）领域有许多库和工具可供使用，涵盖了各种不同的任务和技术。以下是一些常用的NLP库和工具，包括但不限于：</p>
<ol>
<li>**NLTK (Natural Language Toolkit)**：NLTK是Python中最常用的NLP库之一，提供了丰富的工具和资源，用于词性标注、句法分析、语义分析等任务。</li>
<li><strong>spaCy</strong>：spaCy是另一个流行的Python NLP库，提供了快速的词法分析和句法分析等功能，支持多种自然语言处理任务。</li>
<li><strong>Gensim</strong>：Gensim是用于文本处理和主题建模的Python库，支持词向量表示、文档相似性计算等功能。</li>
<li><strong>Stanford NLP</strong>：Stanford NLP是斯坦福大学开发的一组NLP工具，包括分词器、词性标注器、句法分析器等，提供了Java和Python的接口。</li>
<li><strong>OpenNLP</strong>：OpenNLP是Apache基金会的一个项目，提供了一系列NLP工具，包括分词器、词性标注器、命名实体识别器等。</li>
<li><strong>CoreNLP</strong>：CoreNLP是斯坦福大学的一个NLP工具包，提供了一系列NLP任务的功能，包括句法分析、语义分析、情感分析等。</li>
<li><strong>Spacy</strong>：Spacy是一个用于自然语言处理任务的Python库，具有高效的句法分析和实体识别功能。</li>
<li><strong>TextBlob</strong>：TextBlob是一个简单易用的Python库，提供了文本处理和情感分析等功能。</li>
<li><strong>Word2Vec</strong>：Word2Vec是Google开发的一个词向量表示工具，用于将词语转换为向量表示，常用于词语相似性计算和文本表示。</li>
<li><strong>FastText</strong>：FastText是Facebook开发的一个词向量表示工具，支持快速训练和使用大规模词向量模型。</li>
</ol>
<p><strong>以下是一些常见的NLP算法：</strong></p>
<ol>
<li><strong>维特比算法（Viterbi Algorithm）</strong>：维特比算法是一种动态规划算法，用于在给定隐马尔可夫模型的情况下，寻找最有可能产生观测序列的隐藏状态序列。这个算法通过在状态空间中动态地计算每个时刻的最佳路径来实现。维特比算法通常用于诸如词性标注、语音识别等序列标注任务中。</li>
<li><strong>BOUND-WELCH算法（Baum-Welch Algorithm）</strong>：BOUND-WELCH算法是一种用于隐马尔可夫模型参数估计的期望最大化（EM）算法的特例。它用于通过观测序列学习隐马尔可夫模型的参数，包括状态转移概率和观测概率。BOUND-WELCH算法通过迭代地调整模型参数，使得观测序列出现的概率最大化。这个算法常用于无监督学习的问题，其中隐藏状态是未知的，但可以通过观测序列进行估计。</li>
<li><strong>词袋模型（Bag of Words，BoW）</strong>：将文本表示为单词的集合，忽略单词的顺序和语法结构，常用于文本分类和情感分析等任务。</li>
<li><strong>TF-IDF（Term Frequency-Inverse Document Frequency）</strong>：用于衡量单词在文档中的重要性，通过词频和逆文档频率来计算单词的权重，常用于文本分类和信息检索等任务。</li>
<li><strong>词嵌入（Word Embedding）</strong>：将单词映射到低维向量空间中，以捕捉单词之间的语义关系，常用的词嵌入模型包括Word2Vec、GloVe、FastText等。</li>
<li><strong>序列标注算法（Sequence Labeling）</strong>：用于给定输入序列中的每个单词标注一个标签，常见的序列标注任务包括词性标注、命名实体识别等。</li>
<li><strong>机器翻译算法（Machine Translation）</strong>：将一种自然语言翻译成另一种自然语言的算法，常用的机器翻译模型包括统计机器翻译（SMT）和神经机器翻译（NMT）等。</li>
<li><strong>情感分析算法（Sentiment Analysis）</strong>：用于分析文本中的情感倾向，常见的情感分析技术包括基于词典的方法、机器学习方法和深度学习方法等。</li>
<li><strong>命名实体识别算法（Named Entity Recognition，NER）</strong>：用于识别文本中具有特定意义的命名实体，如人名、地名、组织机构名等。</li>
<li><strong>文本生成算法（Text Generation）</strong>：用于生成符合语法和语义规则的文本，常见的文本生成技术包括基于规则的方法、统计语言模型和深度学习模型等。</li>
<li><strong>关键词提取算法（Keyword Extraction）</strong>：从文本中自动提取关键词或关键短语，常用于文本摘要、信息检索等应用。</li>
<li><strong>情境理解（Discourse Analysis）</strong>：用于理解文本中句子之间的逻辑关系和语义关联，常见的技术包括共指消解、指代消解等。</li>
</ol>
<p>这些算法和技术在NLP领域的不同任务和应用中起着重要作用，可以根据具体的需求和场景选择合适的算法来解决问题。</p>
<h2 id="一些具体的例子"><a href="#一些具体的例子" class="headerlink" title="一些具体的例子"></a>一些具体的例子</h2><p><strong>一个语言学+深度学习的例子：</strong></p>
<p><img src="/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/image-20240303162518422.png" alt="image-20240303162518422"></p>
<p><strong>一个依存树的例子：</strong></p>
<p><img src="/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/image-20240303162702975.png" alt="image-20240303162702975"></p>
<p>更加详细的笔记查看：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/mantch/p/12327735.html">https://www.cnblogs.com/mantch/p/12327735.html</a></p>
<p><strong>另外一个是Constituency trees（构成树）。</strong></p>
<p>Constituency trees（构成树）是自然语言处理中一种常用的句法结构表示方法，用于描述句子的成分结构。构成树将句子分解为不同的成分（或短语），并显示它们之间的层次关系。在构成树中，句子被分解为若干个成分，每个成分可以是单词或者更大的短语。这些成分通过树形结构相互连接，其中树的叶子节点对应于句子中的单词，而内部节点表示短语结构。</p>
<p>例如，考虑以下句子：”The cat sat on the mat.”（猫坐在垫子上。）</p>
<p>构成树的示例可能如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">        Sentence</span><br><span class="line">           |</span><br><span class="line">     ______|______</span><br><span class="line">    |             |</span><br><span class="line">  NP (The)       VP (sat)</span><br><span class="line">    |             |</span><br><span class="line">   / \           / \</span><br><span class="line">Det  N         V   PP</span><br><span class="line"> |   |         |   / \</span><br><span class="line"> the cat      sat  P   NP</span><br><span class="line">               |    |   |</span><br><span class="line">               on   the mat</span><br></pre></td></tr></table></figure>

<p>在这个示例中，构成树以”Sentence”作为根节点，该句子被分解为名词短语（NP）”The cat” 和动词短语（VP）”sat on the mat”。名词短语”NP”由限定词（Det）”The”和名词（N）”cat”组成，动词短语”VP”由动词（V）”sat”和介词短语（PP）”on the mat”组成。</p>
<p>构成树提供了对句子结构的直观理解，有助于理解句子中不同部分之间的语法关系。它在自然语言处理中被广泛应用，例如句法分析、语言生成等任务中。</p>
<p><strong>情感分析（sentiment analysis）</strong></p>
<p>情感分析（Sentiment Analysis），也称为意见挖掘（Opinion Mining），是一种自然语言处理技术，旨在识别和提取文本中的情感和情绪。它通常用于分析文本的态度、情绪、观点和情感倾向，以了解作者对某个主题或实体的态度是正面的、负面的还是中性的。</p>
<p>情感分析可以应用于各种类型的文本数据，包括社交媒体帖子、产品评论、新闻文章、调查问卷等。它可以帮助企业了解客户对其产品和服务的感受，政府了解公众对政策和事件的反应，以及分析师了解市场情绪和趋势。</p>
<p>情感分析的任务通常包括以下几个方面：</p>
<ol>
<li><strong>情感极性分类</strong>：将文本分类为积极、消极或中性情感。例如，判断一篇产品评论是正面的、负面的还是中性的。</li>
<li><strong>情感强度分析</strong>：确定文本中情感的强度程度。例如，判断一篇评论中的情感是强烈的还是弱化的。</li>
<li><strong>主题情感分析</strong>：针对特定主题或实体分析情感。例如，针对某个产品或品牌进行情感分析，了解公众对其的态度。</li>
<li><strong>情感趋势分析</strong>：分析情感随时间的变化趋势。例如，追踪产品评论的情感趋势，了解产品在市场上的表现如何随着时间推移而变化。</li>
</ol>
<p>一个例子：</p>
<p><img src="/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/image-20240303163722854.png" alt="image-20240303163722854"></p>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><p>神经网络是受人脑结构启发的计算机模型。神经网络通常简称为神经网络。 </p>
<p>人脑由大约 1000 亿个称为<strong>神经元</strong>的神经细胞组成，每个神经元都与其他神经元相连。</p>
<p><em>电信号沿着称为树突的</em>通道流入神经元，如果这些电输入的总和超过特定<em>阈值</em>，神经元就会通过称为<em>轴突</em>的通道发出电输出。  </p>
<p>为了在计算机内部构建<em>神经网络，我们只需将这些神经元的集合放在一起，这样一些神经元的输出就会馈送到其他神经元的输入。</em></p>
<p>典型的神经网络具有一个 <strong>输入层</strong> （您正在使用的数据中的每个特征有一个输入）、一个 <strong>输出层</strong> （每个目标变量有一个输出）以及 中间的一个或多个神经元<strong>隐藏层。</strong></p>
<p>每个神经元通过权重连接到其他神经元，权重决定每个神经元对其连接的其他神经元的影响程度。</p>
<p>图示：</p>
<p><img src="/2024/03/03/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/image-20240303164126043.png" alt="image-20240303164126043"></p>
<p>在线调参地址：<a target="_blank" rel="noopener" href="https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.27180&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false">https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.27180&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false</a></p>
<h2 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h2>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/NLP/" rel="tag"># NLP</a>
              <a href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" rel="tag"># 自然语言处理</a>
              <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" rel="tag"># 人工智能</a>
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/02/15/Learning-how-to-learn/" rel="prev" title="Learning how to learn">
                  <i class="fa fa-chevron-left"></i> Learning how to learn
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/12/26/%E7%AC%AC%E4%B8%80%E4%B8%AA%E4%BA%BA%E7%94%9F%E4%B8%83%E5%B9%B4%E8%AE%A1%E5%88%92/" rel="next" title="第一个人生七年计划">
                  第一个人生七年计划 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ye Jiu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.5.0/pjax.min.js" integrity="sha256-3NkoLDrmHLTYj7csHIZSr0MHAFTXth7Ua/DDt4MRUAg=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script>

  





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"ams","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
